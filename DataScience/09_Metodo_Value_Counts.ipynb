{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-title",
   "metadata": {},
   "source": [
    "# ğŸ“Š MÃ©todo `value_counts()` en Pandas\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **Objetivo del Tutorial**\n",
    "Aprender a utilizar el mÃ©todo `value_counts()` para contar frecuencias de valores Ãºnicos en columnas categÃ³ricas y numÃ©ricas.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ **Ãndice de Contenidos**\n",
    "\n",
    "1. [ğŸ”§ ConfiguraciÃ³n Inicial](#configuracion)\n",
    "2. [ğŸ“ Carga de Datos](#carga-datos)\n",
    "3. [ğŸ” ExploraciÃ³n BÃ¡sica](#exploracion)\n",
    "4. [ğŸ“Š MÃ©todo value_counts() BÃ¡sico](#value-counts-basico)\n",
    "5. [ğŸ“ˆ Frecuencias Relativas](#frecuencias-relativas)\n",
    "6. [ğŸ¨ ParÃ¡metros Avanzados](#parametros-avanzados)\n",
    "7. [ğŸ“Š VisualizaciÃ³n de Resultados](#visualizacion)\n",
    "8. [ğŸ’¡ Casos de Uso PrÃ¡cticos](#casos-uso)\n",
    "9. [ğŸ“ Resumen y Conclusiones](#resumen)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configuracion",
   "metadata": {},
   "source": [
    "## ğŸ”§ 1. ConfiguraciÃ³n Inicial\n",
    "\n",
    "Importamos las librerÃ­as necesarias para nuestro anÃ¡lisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š ImportaciÃ³n de librerÃ­as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ğŸ¨ ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(f\"ğŸ“¦ Pandas versiÃ³n: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy versiÃ³n: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "carga-datos",
   "metadata": {},
   "source": [
    "## ğŸ“ 2. Carga de Datos\n",
    "\n",
    "Trabajaremos con un dataset de rendimiento estudiantil que contiene informaciÃ³n demogrÃ¡fica y calificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“– Carga del dataset\n",
    "try:\n",
    "    df_exams = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "    print(\"âœ… Dataset cargado exitosamente\")\n",
    "    print(f\"ğŸ“Š Dimensiones: {df_exams.shape[0]} filas Ã— {df_exams.shape[1]} columnas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Archivo no encontrado. Creando dataset de ejemplo...\")\n",
    "    # Crear dataset de ejemplo si no existe el archivo\n",
    "    np.random.seed(42)\n",
    "    df_exams = pd.DataFrame({\n",
    "        'gender': np.random.choice(['female', 'male'], 1000, p=[0.52, 0.48]),\n",
    "        'race/ethnicity': np.random.choice(['group A', 'group B', 'group C', 'group D', 'group E'], 1000),\n",
    "        'parental level of education': np.random.choice([\n",
    "            'some college', \"associate's degree\", 'high school', \n",
    "            'some high school', \"bachelor's degree\", \"master's degree\"\n",
    "        ], 1000, p=[0.23, 0.22, 0.20, 0.18, 0.12, 0.05]),\n",
    "        'lunch': np.random.choice(['standard', 'free/reduced'], 1000, p=[0.65, 0.35]),\n",
    "        'test preparation course': np.random.choice(['none', 'completed'], 1000, p=[0.64, 0.36]),\n",
    "        'math score': np.random.randint(0, 101, 1000),\n",
    "        'reading score': np.random.randint(0, 101, 1000),\n",
    "        'writing score': np.random.randint(0, 101, 1000)\n",
    "    })\n",
    "    print(\"âœ… Dataset de ejemplo creado\")\n",
    "\n",
    "# ğŸ‘€ Vista previa de los datos\n",
    "df_exams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exploracion",
   "metadata": {},
   "source": [
    "## ğŸ” 3. ExploraciÃ³n BÃ¡sica\n",
    "\n",
    "Antes de usar `value_counts()`, exploremos la estructura de nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ InformaciÃ³n general del dataset\n",
    "print(\"ğŸ“Š INFORMACIÃ“N GENERAL DEL DATASET\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“ Forma del DataFrame: {df_exams.shape}\")\n",
    "print(f\"ğŸ”¢ Total de registros: {len(df_exams)}\")\n",
    "print(f\"ğŸ“ Columnas disponibles: {list(df_exams.columns)}\")\n",
    "print(\"\\nğŸ“Š Tipos de datos:\")\n",
    "print(df_exams.dtypes)\n",
    "print(\"\\nğŸ” Valores nulos por columna:\")\n",
    "print(df_exams.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "value-counts-basico",
   "metadata": {},
   "source": [
    "## ğŸ“Š 4. MÃ©todo value_counts() BÃ¡sico\n",
    "\n",
    "### ğŸ¯ Â¿QuÃ© es `value_counts()`?\n",
    "\n",
    "El mÃ©todo `value_counts()` es una herramienta fundamental en Pandas que nos permite:\n",
    "- ğŸ”¢ **Contar** la frecuencia de cada valor Ãºnico en una Serie\n",
    "- ğŸ“ˆ **Ordenar** los resultados por frecuencia (descendente por defecto)\n",
    "- ğŸ“Š **Analizar** la distribuciÃ³n de datos categÃ³ricos\n",
    "\n",
    "### ğŸš€ Uso BÃ¡sico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¢ Contar total de elementos en la columna 'gender'\n",
    "print(\"ğŸ“Š CONTEO TOTAL DE ELEMENTOS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"ğŸ”¢ Total elementos con len(): {len(df_exams['gender'])}\")\n",
    "print(f\"ğŸ”¢ Total elementos con count(): {df_exams['gender'].count()}\")\n",
    "print(f\"ğŸ“ Diferencia: len() incluye NaN, count() los excluye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "value-counts-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘¥ AnÃ¡lisis de distribuciÃ³n por gÃ©nero\n",
    "print(\"ğŸ‘¥ DISTRIBUCIÃ“N POR GÃ‰NERO\")\n",
    "print(\"=\" * 25)\n",
    "gender_counts = df_exams[\"gender\"].value_counts()\n",
    "print(gender_counts)\n",
    "\n",
    "print(\"\\nğŸ“Š InterpretaciÃ³n:\")\n",
    "for gender, count in gender_counts.items():\n",
    "    percentage = (count / gender_counts.sum()) * 100\n",
    "    print(f\"  {gender.title()}: {count} estudiantes ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frecuencias-relativas",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 5. Frecuencias Relativas\n",
    "\n",
    "Las frecuencias relativas nos muestran la proporciÃ³n de cada categorÃ­a respecto al total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-freq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Frecuencias relativas (proporciones)\n",
    "print(\"ğŸ“ˆ FRECUENCIAS RELATIVAS - GÃ‰NERO\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Frecuencias relativas bÃ¡sicas\n",
    "rel_freq = df_exams[\"gender\"].value_counts(normalize=True)\n",
    "print(\"ğŸ”¢ Proporciones decimales:\")\n",
    "print(rel_freq)\n",
    "\n",
    "# Frecuencias relativas redondeadas\n",
    "print(\"\\nğŸ“Š Proporciones redondeadas (2 decimales):\")\n",
    "rel_freq_rounded = df_exams[\"gender\"].value_counts(normalize=True).round(2)\n",
    "print(rel_freq_rounded)\n",
    "\n",
    "# Convertir a porcentajes\n",
    "print(\"\\nğŸ“ˆ Porcentajes:\")\n",
    "percentages = (df_exams[\"gender\"].value_counts(normalize=True) * 100).round(1)\n",
    "for gender, pct in percentages.items():\n",
    "    print(f\"  {gender.title()}: {pct}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parametros-avanzados",
   "metadata": {},
   "source": [
    "## ğŸ¨ 6. ParÃ¡metros Avanzados de value_counts()\n",
    "\n",
    "Exploremos los parÃ¡metros mÃ¡s Ãºtiles del mÃ©todo `value_counts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "education-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ AnÃ¡lisis del nivel educativo de los padres\n",
    "print(\"ğŸ“ NIVEL EDUCATIVO DE LOS PADRES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "education_counts = df_exams[\"parental level of education\"].value_counts()\n",
    "print(\"ğŸ“Š Frecuencias absolutas:\")\n",
    "print(education_counts)\n",
    "\n",
    "print(\"\\nğŸ“ˆ Frecuencias relativas (porcentajes):\")\n",
    "education_pct = df_exams[\"parental level of education\"].value_counts(normalize=True).round(2)\n",
    "for edu, pct in education_pct.items():\n",
    "    print(f\"  {edu.title()}: {pct*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-parameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ParÃ¡metros avanzados de value_counts()\n",
    "print(\"ğŸ”§ PARÃMETROS AVANZADOS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# 1. Ordenamiento ascendente\n",
    "print(\"ğŸ“ˆ 1. Ordenamiento ascendente (ascending=True):\")\n",
    "print(df_exams[\"gender\"].value_counts(ascending=True))\n",
    "\n",
    "# 2. Incluir valores NaN (si los hubiera)\n",
    "print(\"\\nğŸ” 2. Incluir valores NaN (dropna=False):\")\n",
    "print(df_exams[\"gender\"].value_counts(dropna=False))\n",
    "\n",
    "# 3. Limitar resultados\n",
    "print(\"\\nğŸ” 3. Top 3 niveles educativos mÃ¡s comunes:\")\n",
    "top_education = df_exams[\"parental level of education\"].value_counts().head(3)\n",
    "print(top_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-binning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š value_counts() con datos numÃ©ricos (binning)\n",
    "print(\"ğŸ“Š VALUE_COUNTS CON DATOS NUMÃ‰RICOS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Crear bins para las calificaciones de matemÃ¡ticas\n",
    "print(\"ğŸ”¢ DistribuciÃ³n de calificaciones de matemÃ¡ticas por rangos:\")\n",
    "math_bins = pd.cut(df_exams['math score'], \n",
    "                   bins=[0, 50, 70, 85, 100], \n",
    "                   labels=['Bajo (0-50)', 'Medio (51-70)', 'Alto (71-85)', 'Excelente (86-100)'])\n",
    "\n",
    "math_distribution = math_bins.value_counts()\n",
    "print(math_distribution)\n",
    "\n",
    "print(\"\\nğŸ“ˆ Porcentajes por rango:\")\n",
    "math_pct = math_bins.value_counts(normalize=True) * 100\n",
    "for range_name, pct in math_pct.items():\n",
    "    print(f\"  {range_name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualizacion",
   "metadata": {},
   "source": [
    "## ğŸ“Š 7. VisualizaciÃ³n de Resultados\n",
    "\n",
    "Complementemos nuestro anÃ¡lisis con visualizaciones atractivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š VisualizaciÃ³n de los resultados de value_counts()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ“Š AnÃ¡lisis de Distribuciones con value_counts()', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. DistribuciÃ³n por gÃ©nero\n",
    "gender_counts = df_exams['gender'].value_counts()\n",
    "axes[0,0].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', \n",
    "              colors=['#FF6B9D', '#4ECDC4'], startangle=90)\n",
    "axes[0,0].set_title('ğŸ‘¥ DistribuciÃ³n por GÃ©nero', fontweight='bold')\n",
    "\n",
    "# 2. Nivel educativo de padres\n",
    "education_counts = df_exams['parental level of education'].value_counts()\n",
    "axes[0,1].barh(education_counts.index, education_counts.values, color='skyblue')\n",
    "axes[0,1].set_title('ğŸ“ Nivel Educativo de Padres', fontweight='bold')\n",
    "axes[0,1].set_xlabel('NÃºmero de Estudiantes')\n",
    "\n",
    "# 3. Tipo de almuerzo\n",
    "lunch_counts = df_exams['lunch'].value_counts()\n",
    "axes[1,0].bar(lunch_counts.index, lunch_counts.values, color=['#95E1D3', '#F38BA8'])\n",
    "axes[1,0].set_title('ğŸ½ï¸ Tipo de Almuerzo', fontweight='bold')\n",
    "axes[1,0].set_ylabel('NÃºmero de Estudiantes')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Curso de preparaciÃ³n\n",
    "prep_counts = df_exams['test preparation course'].value_counts()\n",
    "axes[1,1].pie(prep_counts.values, labels=prep_counts.index, autopct='%1.1f%%',\n",
    "              colors=['#FFB4B4', '#B4E7CE'], startangle=90)\n",
    "axes[1,1].set_title('ğŸ“š Curso de PreparaciÃ³n', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casos-uso",
   "metadata": {},
   "source": [
    "## ğŸ’¡ 8. Casos de Uso PrÃ¡cticos\n",
    "\n",
    "Veamos algunos casos prÃ¡cticos donde `value_counts()` es especialmente Ãºtil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-cases",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¡ Caso 1: DetecciÃ³n de valores atÃ­picos o poco frecuentes\n",
    "print(\"ğŸ” CASO 1: DETECCIÃ“N DE VALORES POCO FRECUENTES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "race_counts = df_exams['race/ethnicity'].value_counts()\n",
    "print(\"ğŸ“Š DistribuciÃ³n por grupo Ã©tnico:\")\n",
    "print(race_counts)\n",
    "\n",
    "# Identificar grupos minoritarios (menos del 15% del total)\n",
    "total_students = len(df_exams)\n",
    "minority_threshold = 0.15 * total_students\n",
    "\n",
    "print(f\"\\nğŸ¯ Grupos minoritarios (< {minority_threshold:.0f} estudiantes):\")\n",
    "minority_groups = race_counts[race_counts < minority_threshold]\n",
    "if len(minority_groups) > 0:\n",
    "    for group, count in minority_groups.items():\n",
    "        pct = (count / total_students) * 100\n",
    "        print(f\"  {group}: {count} estudiantes ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"  No se encontraron grupos minoritarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¡ Caso 2: Control de calidad de datos\n",
    "print(\"ğŸ” CASO 2: CONTROL DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Verificar valores Ãºnicos en cada columna categÃ³rica\n",
    "categorical_columns = ['gender', 'race/ethnicity', 'parental level of education', \n",
    "                      'lunch', 'test preparation course']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    unique_values = df_exams[col].value_counts()\n",
    "    print(f\"\\nğŸ“‹ {col.upper()}:\")\n",
    "    print(f\"  ğŸ”¢ Valores Ãºnicos: {len(unique_values)}\")\n",
    "    print(f\"  ğŸ“Š DistribuciÃ³n: {dict(unique_values)}\")\n",
    "    \n",
    "    # Detectar posibles inconsistencias (valores con muy baja frecuencia)\n",
    "    low_freq = unique_values[unique_values < 5]\n",
    "    if len(low_freq) > 0:\n",
    "        print(f\"  âš ï¸  Valores con baja frecuencia: {dict(low_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¡ Caso 3: AnÃ¡lisis comparativo\n",
    "print(\"ğŸ“Š CASO 3: ANÃLISIS COMPARATIVO\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Comparar distribuciones entre diferentes grupos\n",
    "print(\"ğŸ”„ ComparaciÃ³n: Curso de preparaciÃ³n vs GÃ©nero\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Crear tabla cruzada\n",
    "cross_tab = pd.crosstab(df_exams['gender'], df_exams['test preparation course'], \n",
    "                       margins=True, normalize='index')\n",
    "print(\"ğŸ“Š Proporciones por gÃ©nero:\")\n",
    "print(cross_tab.round(3))\n",
    "\n",
    "# AnÃ¡lisis por separado\n",
    "print(\"\\nğŸ‘¥ AnÃ¡lisis detallado:\")\n",
    "for gender in df_exams['gender'].unique():\n",
    "    gender_data = df_exams[df_exams['gender'] == gender]\n",
    "    prep_dist = gender_data['test preparation course'].value_counts(normalize=True)\n",
    "    print(f\"\\n  {gender.title()}:\")\n",
    "    for course, pct in prep_dist.items():\n",
    "        print(f\"    {course}: {pct:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resumen",
   "metadata": {},
   "source": [
    "## ğŸ“ 9. Resumen y Conclusiones\n",
    "\n",
    "### ğŸ¯ **Puntos Clave del MÃ©todo value_counts()**\n",
    "\n",
    "| Aspecto | DescripciÃ³n | Ejemplo |\n",
    "|---------|-------------|----------|\n",
    "| ğŸ¯ **PropÃ³sito** | Contar frecuencias de valores Ãºnicos | `df['columna'].value_counts()` |\n",
    "| ğŸ“Š **Ordenamiento** | Por defecto ordena descendente | `ascending=True` para ascendente |\n",
    "| ğŸ“ˆ **Frecuencias Relativas** | Usar `normalize=True` | Obtiene proporciones del total |\n",
    "| ğŸ” **Valores Nulos** | Por defecto los excluye | `dropna=False` para incluirlos |\n",
    "| ğŸ¨ **PersonalizaciÃ³n** | MÃºltiples parÃ¡metros disponibles | `sort`, `bins`, etc. |\n",
    "\n",
    "### ğŸ’¡ **Casos de Uso Principales**\n",
    "\n",
    "1. **ğŸ“Š AnÃ¡lisis Exploratorio**: Entender la distribuciÃ³n de variables categÃ³ricas\n",
    "2. **ğŸ” Control de Calidad**: Detectar valores atÃ­picos o inconsistencias\n",
    "3. **ğŸ“ˆ AnÃ¡lisis de Frecuencias**: Calcular proporciones y porcentajes\n",
    "4. **ğŸ¯ SegmentaciÃ³n**: Identificar grupos mayoritarios y minoritarios\n",
    "5. **ğŸ“‹ Reportes**: Generar resÃºmenes estadÃ­sticos rÃ¡pidos\n",
    "\n",
    "### ğŸš€ **Mejores PrÃ¡cticas**\n",
    "\n",
    "- âœ… **Siempre verificar** el tipo de datos antes de aplicar `value_counts()`\n",
    "- âœ… **Usar `normalize=True`** cuando necesites proporciones\n",
    "- âœ… **Combinar con visualizaciones** para mejor comprensiÃ³n\n",
    "- âœ… **Considerar el contexto** al interpretar los resultados\n",
    "- âœ… **Documentar hallazgos** importantes para futuros anÃ¡lisis\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‰ **Â¡Felicitaciones!**\n",
    "\n",
    "Has completado el tutorial sobre el mÃ©todo `value_counts()` en Pandas. Ahora tienes las herramientas necesarias para:\n",
    "\n",
    "- ğŸ”¢ Contar frecuencias de manera eficiente\n",
    "- ğŸ“Š Analizar distribuciones de datos categÃ³ricos\n",
    "- ğŸ“ˆ Calcular proporciones y porcentajes\n",
    "- ğŸ¨ Personalizar el anÃ¡lisis segÃºn tus necesidades\n",
    "- ğŸ’¡ Aplicar estos conocimientos en casos reales\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“š PrÃ³ximos pasos sugeridos:**\n",
    "- Explorar mÃ©todos relacionados como `crosstab()` y `pivot_table()`\n",
    "- Practicar con diferentes tipos de datasets\n",
    "- Combinar `value_counts()` con tÃ©cnicas de visualizaciÃ³n avanzadas\n",
    "\n",
    "---\n",
    "\n",
    "*ğŸ’¡ **Tip**: Guarda este notebook como referencia para futuros proyectos de anÃ¡lisis de datos.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}